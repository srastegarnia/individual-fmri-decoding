{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from load_confounds import Params9, Params24\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = 1.49\n",
    "subject = 'sub-01'\n",
    "task_modality = 'motor'\n",
    "\n",
    "out_path = '/home/SRastegarnia/hcptrt_decoding_Shima/hcptrt_decoding/timeseries_benchmark/outputs/'\n",
    "bold_suf = 'space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'\n",
    "# mod_ev_suf = '{}_ses-001_task-restingstate_run-01_events.tsv'.format()\n",
    "\n",
    "data_path = glob.glob('/data/neuromod/DATA/cneuromod/hcptrt/derivatives/'\\\n",
    "                     'fmriprep-20.1.0/fmriprep/{}/**/*{}*'\n",
    "                     .format(subject, task_modality) + bold_suf, recursive=True)\n",
    "\n",
    "events_path = glob.glob('/data/neuromod/DATA/cneuromod/hcptrt/'\\\n",
    "                     '{}/**/func/*{}*_events.tsv'\n",
    "                     .format(subject, task_modality), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "['/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-006/func/sub-01_ses-006_task-motor_run-01_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-006/func/sub-01_ses-006_task-motor_run-02_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-001/func/sub-01_ses-001_task-motor_run-01_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-005/func/sub-01_ses-005_task-motor_run-02_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-005/func/sub-01_ses-005_task-motor_run-01_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-008/func/sub-01_ses-008_task-motor_run-01_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-008/func/sub-01_ses-008_task-motor_run-02_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-002/func/sub-01_ses-002_task-motor_run-01_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-002/func/sub-01_ses-002_task-motor_run-02_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-007/func/sub-01_ses-007_task-motor_run-01_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-003/func/sub-01_ses-003_task-motor_run-01_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-009/func/sub-01_ses-009_task-motor_run-01_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-010/func/sub-01_ses-010_task-motor_run-02_events.tsv', '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-010/func/sub-01_ses-010_task-motor_run-01_events.tsv']\n"
     ]
    }
   ],
   "source": [
    "# Remove the data with 160 volumes\n",
    "data_path.remove('/data/neuromod/DATA/cneuromod/hcptrt/derivatives/'\\\n",
    "                 'fmriprep-20.1.0/fmriprep/sub-01/ses-004/func/'\\\n",
    "                 'sub-01_ses-004_task-motor_run-1_space-MNI152NLin2009cAsym_'\\\n",
    "                 'desc-preproc_bold.nii.gz')\n",
    "\n",
    "events_path.remove('/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-004/'\\\n",
    "                   'func/sub-01_ses-004_task-motor_run-01_events.tsv')\n",
    "\n",
    "print(type(data_path))\n",
    "print(type(events_path))\n",
    "print(events_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of bold files: 14\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-008/func/sub-01_ses-008_task-motor_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-008/func/sub-01_ses-008_task-motor_run-2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-002/func/sub-01_ses-002_task-motor_run-2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-002/func/sub-01_ses-002_task-motor_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-005/func/sub-01_ses-005_task-motor_run-2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-005/func/sub-01_ses-005_task-motor_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-001/func/sub-01_ses-001_task-motor_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-006/func/sub-01_ses-006_task-motor_run-2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-006/func/sub-01_ses-006_task-motor_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-010/func/sub-01_ses-010_task-motor_run-2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-010/func/sub-01_ses-010_task-motor_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-003/func/sub-01_ses-003_task-motor_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-009/func/sub-01_ses-009_task-motor_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "/data/neuromod/DATA/cneuromod/hcptrt/derivatives/fmriprep-20.1.0/fmriprep/sub-01/ses-007/func/sub-01_ses-007_task-motor_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "(144, 444)\n",
      "######### Reading Nifiti files is done! #########\n"
     ]
    }
   ],
   "source": [
    "print('The number of bold files:', len(data_path))\n",
    "\n",
    "bold_files=[]\n",
    "\n",
    "for path in data_path: \n",
    "    print(path)    \n",
    "    masker= NiftiLabelsMasker(labels_img='MIST_444.nii.gz', standardize=True, \n",
    "                              detrend=False, smoothing_fwhm=8).fit()\n",
    "    Data_fmri=masker.transform(path, confounds=Params9().load(path))\n",
    "    print(Data_fmri.shape)\n",
    "    bold_files.append(Data_fmri)\n",
    "\n",
    "bold_outname = out_path + 'fMRI2.npy'\n",
    "np.save(bold_outname, bold_files)\n",
    "print('######### Reading Nifiti files is done! #########')\n",
    "\n",
    "if len(events_path) != len(bold_files):\n",
    "    print('Miss-matching between events and fmri files')\n",
    "    print('Number of Nifti files:' ,len(bold_files))\n",
    "    print('Number of events files:' ,len(events_path))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(Data_fmri.shape[0])\n",
    "print(type(Data_fmri))\n",
    "i = Data_fmri.shape[0]\n",
    "print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bold files lenght: 14\n",
      "bold files type: <class 'list'>\n",
      "events files lenght: 14\n",
      "events files type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print('bold files lenght:', len(bold_files))\n",
    "print('bold files type:',type(bold_files))\n",
    "\n",
    "print('events files lenght:', len(events_path))\n",
    "print('events files type:',type(events_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking modified evevt with just one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_check_path = '/data/neuromod/DATA/cneuromod/hcptrt/sub-01/ses-001/func/'\n",
    "ev_file = ev_check_path + 'sub-01_ses-001_task-motor_run-01_events.tsv'\n",
    "temp_ev = pd.read_csv(ev_file, sep='\\t',encoding=\"utf8\",\n",
    "                      header = 0)\n",
    "pd.set_option('display.max_rows', temp_ev.shape[0]+1)\n",
    "rows = len(temp_ev.axes[0])\n",
    "cols = len(temp_ev.axes[1])\n",
    "\n",
    "# vol_no = np.ceil((temp_ev.duration/TR)).astype(int)\n",
    "# vol_no = np.round((temp_ev.duration/TR)).astype(int)\n",
    "# temp_ev.insert(3, 'volume_no', vol_no)\n",
    "\n",
    "print(temp_ev)  \n",
    "print(\"Number of Rows: \", rows)\n",
    "print(\"Number of Columns: \", cols)\n",
    "\n",
    "###############################################################\n",
    "task_dur = []\n",
    "task_mod = ['countdown']\n",
    "a = 0\n",
    "\n",
    "for i in range(1, rows):\n",
    "    if (temp_ev.iloc[i]['trial_type'] != temp_ev.iloc[i-1]['trial_type']):\n",
    "        task_mod.append(temp_ev.iloc[i]['trial_type'])\n",
    "        dur = (temp_ev.iloc[i]['onset']) - (temp_ev.iloc[a]['onset'])\n",
    "        task_dur.append(dur)\n",
    "        a = i\n",
    "        \n",
    "task_dur.append(temp_ev.iloc[i]['duration'])\n",
    "\n",
    "if (len(task_dur) != len(task_mod)):\n",
    "    print('error: tasks and durations do not match')\n",
    "\n",
    "print(task_mod)\n",
    "print(len(task_mod))\n",
    "print(task_dur)\n",
    "print(len(task_dur))\n",
    "\n",
    "###############################################################\n",
    "print(type(task_dur))\n",
    "\n",
    "task_dur = np.array(task_dur)\n",
    "print(type(task_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_no_ciel = []\n",
    "vol_no_round = []\n",
    "vol_no_floor = []\n",
    "\n",
    "for t in task_dur:\n",
    "#     a = t+0.54900000000001\n",
    "    a = t + 0.2\n",
    "#     print(a)\n",
    "    vol_ciel = np.ceil(t/TR).astype(int)\n",
    "    vol_no_ciel.append(vol_ciel)\n",
    "    \n",
    "    vol_round = np.round((a)/TR).astype(int)\n",
    "    vol_no_round.append(vol_round)\n",
    "    \n",
    "    vol_floor= np.floor(t/TR).astype(int)\n",
    "    vol_no_floor.append(vol_floor)\n",
    "    \n",
    "print(vol_no_ciel)\n",
    "print(vol_no_round)\n",
    "print(vol_no_floor)\n",
    "\n",
    "###############################################################\n",
    "def _sum(arr): \n",
    "    sum=0\n",
    "    for i in arr:\n",
    "        sum = sum + i\n",
    "          \n",
    "    return(sum) \n",
    "\n",
    "ans_ciel = _sum(vol_no_ciel)\n",
    "ans_round = _sum(vol_no_round)\n",
    "ans_floor= _sum(vol_no_floor) \n",
    "\n",
    "print ('Ciel sum of the array is', ans_ciel) \n",
    "print ('Round sum of the array is', ans_round)\n",
    "print ('Floor sum of the array is', ans_floor) \n",
    "print('Volume considering modality duration:', _sum(task_dur)/TR)\n",
    "print('All scan duration:', _sum(task_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(task_mod)\n",
    "# print(vol_no_round)\n",
    "\n",
    "final_array = []\n",
    "if (len(task_mod) == len(task_dur) == len(vol_no_round)):\n",
    "    for l in range (len(task_mod)):\n",
    "        f= ((task_mod[l],)*vol_no_round[l])\n",
    "        final_array.append(f)\n",
    "        \n",
    "# print(final_array)\n",
    "print(len(final_array))\n",
    "print(type(final_array))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in final_array for item in sublist]\n",
    "volume_labels = np.array(flat_list)\n",
    "\n",
    "print(volume_labels.shape)\n",
    "print(type(volume_labels))\n",
    "print('Volume labels:', volume_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating labels files for all the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_event_files(events_path):   \n",
    "\n",
    "labels_files=[]\n",
    "for event in events_path:\n",
    "\n",
    "    task_dur = []\n",
    "    task_mod = ['countdown']\n",
    "    a = 0\n",
    "\n",
    "    ev_temp = pd.read_csv(event,sep=\"\\t\",encoding=\"utf8\", header = 0)\n",
    "    rows_no = len(ev_temp.axes[0])\n",
    "    cols_no = len(ev_temp.axes[1])\n",
    "\n",
    "    for i in range(1, rows_no):\n",
    "        if (ev_temp.iloc[i]['trial_type'] != ev_temp.iloc[i-1]['trial_type']):\n",
    "            task_mod.append(ev_temp.iloc[i]['trial_type'])\n",
    "            dur = (ev_temp.iloc[i]['onset']) - (ev_temp.iloc[a]['onset'])\n",
    "            task_dur.append(dur)\n",
    "            a = i\n",
    "\n",
    "    # Adds the last tcondition (cross_fixation)\n",
    "    task_dur.append(ev_temp.iloc[i]['duration'])\n",
    "\n",
    "    if (len(task_dur) != len(task_mod)):\n",
    "        print('error: tasks and durations do not match')\n",
    "\n",
    "    task_dur = np.array(task_dur)\n",
    "    task_mod = np.array(task_mod)\n",
    "\n",
    "    # Generate volume No. array for each task condition\n",
    "    vol_no = []\n",
    "    for t in task_dur:\n",
    "        a = t + 0.2\n",
    "        vol_round = np.round((a)/TR).astype(int)\n",
    "        vol_no.append(vol_round)\n",
    "\n",
    "    # Find the Qty of null ending volumes\n",
    "    def _sum(arr): \n",
    "        sum=0\n",
    "        for i in arr:\n",
    "            sum = sum + i\n",
    "\n",
    "        return(sum) \n",
    "\n",
    "    ans_round = _sum(vol_no)\n",
    "    d = Data_fmri.shape[0] - ans_round        \n",
    "\n",
    "    # Generate timeseries labels considering the volume No.           \n",
    "    final_array = []\n",
    "    if (len(task_mod) == len(task_dur) == len(vol_no)):\n",
    "        for l in range (len(task_mod)):\n",
    "            f= ((task_mod[l],)*vol_no[l])\n",
    "            final_array.append(f)\n",
    "    \n",
    "    # Add the null label for the ending volumes\n",
    "    if d > 0:\n",
    "        end_vol = (('null',)*d)\n",
    "        final_array.append(end_vol)\n",
    "    \n",
    "    # Generate a flat list of labels\n",
    "    flat_list = [item for sublist in final_array for item in sublist]\n",
    "    volume_labels = np.array(flat_list)\n",
    "    \n",
    "    labels_files.append(volume_labels)\n",
    "\n",
    "# Save file to csv \n",
    "labels_file_name = out_path + event.split('func/')[1].split('sub-')[0] + 'events_labels.tsv'\n",
    "savetxt(labels_file_name, labels_files, fmt=\"%s\", delimiter=',', header = 'label')      \n",
    "\n",
    "# # Save file to csv \n",
    "# file_name = out_path + event.split('func/')[1].split('.tsv')[0] + '_labels.tsv'\n",
    "# savetxt(file_name, volume_labels, fmt=\"%s\", delimiter=',', header = 'label')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# print(labels_files.shape)\n",
    "\n",
    "print(type(labels_files))\n",
    "\n",
    "labels_files = np.array(labels_files)\n",
    "print(type(labels_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 144)\n"
     ]
    }
   ],
   "source": [
    "print(labels_files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "(14, 144, 444)\n"
     ]
    }
   ],
   "source": [
    "print(type(bold_files))\n",
    "\n",
    "bold_files= np.array(bold_files)\n",
    "print(type(bold_files))\n",
    "\n",
    "print(bold_files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 1)\n",
      "                                              # label\n",
      "0   countdown,countdown,countdown,countdown,countd...\n",
      "1   countdown,countdown,countdown,countdown,countd...\n",
      "2   countdown,countdown,countdown,countdown,countd...\n",
      "3   countdown,countdown,countdown,countdown,countd...\n",
      "4   countdown,countdown,countdown,countdown,countd...\n",
      "5   countdown,countdown,countdown,countdown,countd...\n",
      "6   countdown,countdown,countdown,countdown,countd...\n",
      "7   countdown,countdown,countdown,countdown,countd...\n",
      "8   countdown,countdown,countdown,countdown,countd...\n",
      "9   countdown,countdown,countdown,countdown,countd...\n",
      "10  countdown,countdown,countdown,countdown,countd...\n",
      "11  countdown,countdown,countdown,countdown,countd...\n",
      "12  countdown,countdown,countdown,countdown,countd...\n",
      "13  countdown,countdown,countdown,countdown,countd...\n"
     ]
    }
   ],
   "source": [
    "# Reading an output label file\n",
    "tsv_read = pd.read_csv(labels_file_name, sep='\\t')\n",
    "\n",
    "# pd.set_option('display.max_rows', tsv_read.shape[0]+1)\n",
    "print(tsv_read.shape)\n",
    "print(tsv_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_block = np.concatenate([label_data_trial_block_new[ii] for ii in range(blocks_num)], axis=0)\n",
    "fmri_data_block = np.concatenate([fmri_data_cnn_block_new[ii] for ii in range(blocks_num)], axis=0)\n",
    "\n",
    "\n",
    "sid = fname.split('_')[0]  # safe since we set the filename\n",
    "nib.save(image.concat_imgs(z_maps), fname)\n",
    "np.savetxt('{}_{}_labels.csv'.format(sid,task_label), condition_idx, fmt='%s')\n",
    "np.savetxt('{}_{}_runs.csv'.format(sid,task_label), session_idx, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data selection\n",
    "X = bold_files\n",
    "y = labels_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (14, 144) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-11c16fbdd334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Encoding the string to numerical values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabelencoder_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelencoder_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    845\u001b[0m     raise ValueError(\n\u001b[1;32m    846\u001b[0m         \u001b[0;34m\"y should be a 1d array, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \"got an array of shape {} instead.\".format(shape))\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (14, 144) instead."
     ]
    }
   ],
   "source": [
    "# Encoding the string to numerical values\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(type(y))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.reshape(y, (144,1))\n",
    "y = test\n",
    "\n",
    "print(y.shape)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "y = pd.DataFrame(enc.fit_transform(y).toarray())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split the data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=True, random_state = 0)\n",
    "\n",
    "#standarize features caling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
