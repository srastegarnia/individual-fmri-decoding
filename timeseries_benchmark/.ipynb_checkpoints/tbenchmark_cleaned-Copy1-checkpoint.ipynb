{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SRastegarnia/.virtualenvs/benchmark_env/lib/python3.6/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "# import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import hcptrt_data_preparation\n",
    "import seaborn as sn\n",
    "from collections import Counter, defaultdict\n",
    "from load_confounds import Params9, Params24\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut, cross_val_score, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from numpy import savetxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from nilearn.plotting import plot_anat, show, plot_stat_map, plot_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = 1.49\n",
    "subject = 'sub-01'\n",
    "modality = 'wm'\n",
    "confound_name = Params9()\n",
    "\n",
    "# event_suffix = '{}_ses-001_task-restingstate_run-01_events.tsv'.format()\n",
    "out_path = '/home/SRastegarnia/hcptrt_decoding_Shima/hcptrt_decoding/'\\\n",
    "            'timeseries_benchmark/outputs_check/'\n",
    "bold_suffix = 'space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'\n",
    "\n",
    "data_path = sorted(glob.glob('/data/neuromod/DATA/cneuromod/hcptrt/derivatives/'\\\n",
    "                     'fmriprep-20.2lts/fmriprep/{}/**/*{}*'\n",
    "                     .format(subject, modality) + bold_suffix, recursive=True))\n",
    "\n",
    "events_path = sorted(glob.glob('/data/neuromod/DATA/cneuromod/hcptrt/'\\\n",
    "                     '{}/**/func/*{}*_events.tsv'\n",
    "                     .format(subject, modality), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of bold files: 15\n",
      "######### Reading Nifiti files is done! #########\n"
     ]
    }
   ],
   "source": [
    "# Done!\n",
    "# def load_fmri_data(subject, modality, confounds): \n",
    "\n",
    "print('The number of bold files:', len(data_path))\n",
    "\n",
    "bold_files = []\n",
    "for dpath in data_path:    \n",
    "    masker = NiftiLabelsMasker(labels_img = 'MIST_444.nii.gz', standardize=True, \n",
    "                              detrend = False, smoothing_fwhm = 5).fit()\n",
    "    data_fmri = masker.transform(dpath, confounds = confound_name.load(dpath))    \n",
    "    bold_files.append(data_fmri)\n",
    "\n",
    "bold_outname = out_path + modality + '_fMRI2.npy'\n",
    "np.save(bold_outname, bold_files)\n",
    "print('######### Reading Nifiti files is done! #########')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 202, 444)\n"
     ]
    }
   ],
   "source": [
    "a = np.load(bold_outname, allow_pickle=True)\n",
    "print(np.shape(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of events files: 15\n",
      "######### Reading events files is done! #########\n"
     ]
    }
   ],
   "source": [
    "# Done!\n",
    "# def load_events_files(events_path, modality)\n",
    "\n",
    "print('The number of events files:', len(events_path))\n",
    "\n",
    "events_files = []\n",
    "for epath in events_path: \n",
    "    event = pd.read_csv(epath, sep = \"\\t\", encoding = \"utf8\", header = 0)\n",
    "    if modality == 'wm':                    \n",
    "        event.trial_type = event.trial_type.astype(str) + '_' + \\\n",
    "        event.stim_type.astype(str)\n",
    "        \n",
    "    if modality == 'relational':                    \n",
    "        event.trial_type = event.trial_type.astype(str) + '_' + \\\n",
    "        event.instruction.astype(str)\n",
    "\n",
    "    events_files.append(event)\n",
    "\n",
    "print('######### Reading events files is done! #########') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bold_outname = '/home/SRastegarnia/hcptrt_decoding_Shima/hcptrt_decoding/'\\\n",
    "##                  'timeseries_benchmark/outputs/motor_fMRI2.npy'\n",
    "\n",
    "# # np.save(bold_outname, bold_files)\n",
    "# print(bold_outname)\n",
    "# a = np.load(bold_outname, allow_pickle=True)\n",
    "# print(np.shape(a))\n",
    "# print(np.shape(a[0]))\n",
    "# print(len(a))\n",
    "# print(bold_files[0].shape)\n",
    "\n",
    "# print(events_files[0])\n",
    "# print(len(events_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done!\n",
    "# def check_input(bold_files, events_files):\n",
    "\n",
    "data_lenght = len(bold_files)\n",
    "data_lenght = int (data_lenght or 0)\n",
    "\n",
    "for i in range(0, data_lenght-1):\n",
    "    if bold_files[i].shape > bold_files[i+1].shape:         \n",
    "        a = np.shape(bold_files[i])[0] - np.shape(bold_files[i+1])[0]        \n",
    "        bold_files[i] = bold_files[i][0:-a, 0:]\n",
    "        print('The bold file number', i, 'had', a, 'extra volumes')\n",
    "\n",
    "if len(events_files) != len(bold_files):\n",
    "    print('Miss-matching between events and fmri files')\n",
    "    print('Number of Nifti files:' ,len(bold_files))\n",
    "    print('Number of events files:' ,len(events_files)) \n",
    "    \n",
    "for d in range(0, data_lenght-1):\n",
    "    if bold_files[d].shape != bold_files[d].shape:\n",
    "        print('There is mismatch in BOLD file size!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating labels files for all the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done!\n",
    "# def volume_labeling(bold_files, events_files, confounds, subject, modality):\n",
    "\n",
    "labels_files = []\n",
    "for events_file in events_files:\n",
    "    task_durations = []\n",
    "    task_modalities = []\n",
    "    row_counter = 0\n",
    "\n",
    "    task_modalities.append(events_file.iloc[0]['trial_type'])\n",
    "    rows_no = len(events_file.axes[0])\n",
    "#     cols_no = len(events_file.axes[1])\n",
    "\n",
    "    for i in range(1, rows_no):\n",
    "        if (events_file.iloc[i]['trial_type'] != events_file.iloc[i-1]['trial_type']):\n",
    "            task_modalities.append(events_file.iloc[i]['trial_type'])\n",
    "            duration = (events_file.iloc[i]['onset']) - \\\n",
    "                        (events_file.iloc[row_counter]['onset'])\n",
    "            task_durations.append(duration)\n",
    "            row_counter = i\n",
    "            \n",
    "    # Adds the last tcondition (cross_fixation)\n",
    "    task_durations.append(events_file.iloc[i]['duration'])\n",
    "\n",
    "    if (len(task_durations) != len(task_modalities)):\n",
    "        print('error: tasks and durations do not match')\n",
    "\n",
    "    task_durations = np.array(task_durations)\n",
    "    task_modalities = np.array(task_modalities)\n",
    "\n",
    "    # Generate volume No. array for each task condition\n",
    "    volume_no = []\n",
    "    for t in task_durations:\n",
    "        volume_round = np.round((t)/TR).astype(int)\n",
    "        volume_no.append(volume_round)\n",
    "\n",
    "    # Find the Qty of null ending volumes\n",
    "    def _sum(arr): \n",
    "        sum = 0\n",
    "        for i in arr:\n",
    "            sum = sum + i\n",
    "        return(sum) \n",
    "\n",
    "    ans_round = _sum(volume_no)\n",
    "    sample_fmri = masker.transform(data_path[0], confounds = confound_name.\n",
    "                                 load(data_path[0]))\n",
    "    null_ending = sample_fmri.shape[0] - ans_round \n",
    "    \n",
    "    # Generate timeseries labels considering the volume No.           \n",
    "    final_array = []\n",
    "    if (len(task_modalities) == len(task_durations) == len(volume_no)):\n",
    "        for l in range (len(task_modalities)):\n",
    "            f = ((task_modalities[l],) * volume_no[l])\n",
    "            final_array.append(f)\n",
    "    \n",
    "    # Add the null label for the ending volumes\n",
    "    if null_ending > 0:\n",
    "        end_volume = (('null',) * null_ending)\n",
    "        final_array.append(end_volume)\n",
    "    \n",
    "    # Generate a flat list of labels\n",
    "    flat_list = [item for sublist in final_array for item in sublist]\n",
    "    volume_labels = np.array(flat_list)  \n",
    "    labels_files.append(volume_labels)\n",
    "\n",
    "# Generate a flat list of labels\n",
    "flat_labels_files = [item for sublist in labels_files for item in sublist]\n",
    "flat_volume_labels = np.array(flat_labels_files)\n",
    "\n",
    "shape = np.shape(bold_files[1])[0]\n",
    "flat_volume_labels = np.reshape(flat_volume_labels, (data_lenght * shape,1))\n",
    "\n",
    "# Generate a flat list of bold matrices\n",
    "flat_bold = [item for sublist in bold_files for item in sublist]\n",
    "flat_bold_files = np.array(flat_bold)  \n",
    "\n",
    "# Cheking the same lenght of the flat bold and label file\n",
    "if (len(flat_bold_files[:, 0]) != len(flat_volume_labels[:, 0])):\n",
    "    print('error: labels and bold flat files mismatche')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def HRFlag_labeling(flat_volume_labels)\n",
    "\n",
    "# Labeling the 3 first volumes of stimulus longer than 5 seconds as HRF_lag\n",
    "HRFlag_volume_labels = []\n",
    "b = 0\n",
    "l = len(flat_volume_labels[:, 0]) \n",
    "\n",
    "while (b < (l- 1)):  \n",
    "    if (flat_volume_labels[b, 0] != flat_volume_labels[b + 1, 0]):\n",
    "        HRFlag_volume_labels.append(flat_volume_labels[b, 0])\n",
    "\n",
    "        if (flat_volume_labels[b + 1, 0] == flat_volume_labels[b + 2, 0] == \n",
    "            flat_volume_labels[b + 3, 0] == flat_volume_labels[b + 4, 0]):\n",
    "            for j in range (1, 4):\n",
    "                HRFlag_volume_labels.append('HRF_lag')\n",
    "            b = b + 4  \n",
    "        else:\n",
    "            b = b + 1\n",
    "            \n",
    "    else:\n",
    "        HRFlag_volume_labels.append(flat_volume_labels[b, 0])\n",
    "        b = b + 1\n",
    "\n",
    "HRFlag_volume_labels.append(flat_volume_labels[l - 1, 0])\n",
    "# HRFlag_volume_labels = np.reshape(HRFlag_volume_labels, (data_lenght*sh,1))\n",
    "\n",
    "# print(len(HRFlag_volume_labels))\n",
    "# for i in range (2000, 2159):\n",
    "#     print(HRFlag_volume_labels[i], ': ', flat_volume_labels[i, 0]) \n",
    "\n",
    "# print(np.shape(flat_volume_labels))\n",
    "# print(np.shape(HRFlag_volume_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(events_files[0].trial_type)\n",
    "unwanted = {'countdown','cross_fixation','Cue','new_bloc_right_hand', \n",
    "            'new_bloc_right_foot','new_bloc_left_foot','new_bloc_tongue', \n",
    "            'new_bloc_left_hand','new_bloc_control','new_bloc_relational',\n",
    "            'new_bloc_shape','new_bloc_face', 'countdown_nan','Cue_nan', 'HRF_lag', 'null'\n",
    "            }\n",
    "categories = [c for c in categories if c not in unwanted]\n",
    "conditions = list(set(categories))\n",
    "num_cond = len(set(categories))\n",
    "# print(num_cond)\n",
    "# print(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_volume_labels = []\n",
    "parcel_no = np.shape(flat_bold_files[1])[0]\n",
    "final_bold_files = np.empty((0, parcel_no), int)\n",
    "\n",
    "for i in range (0, len(HRFlag_volume_labels)):\n",
    "    if (HRFlag_volume_labels[i] not in unwanted):\n",
    "        final_volume_labels.append(HRFlag_volume_labels[i])\n",
    "        final_bold_files = np.append(final_bold_files, \n",
    "                                     np.array([flat_bold_files[i, :]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lable = pd.DataFrame(final_volume_labels)\n",
    "df_lable.to_csv(out_path + modality +'_final_labels.csv', sep=',' ,index=False, header=None)\n",
    "\n",
    "df_fMRI = out_path + modality + '_final_fMRI.npy'\n",
    "np.save(df_fMRI, final_bold_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('parcel numbers:', parcel_no)\n",
    "print('lenght of all volume labels:', len(HRFlag_volume_labels))\n",
    "print('shape of flat_bold_files:', np.shape(flat_bold_files))\n",
    "print(type(final_bold_files))\n",
    "print('lenght of final_volume_labels:', len(final_volume_labels))\n",
    "print(type(final_volume_labels))\n",
    "print('lenght of final_bold_files:', len(final_bold_files))\n",
    "print('shape of final_bold_files:', np.shape(final_bold_files))\n",
    "print('shape of final_volume_labels:', np.shape(final_volume_labels))\n",
    "print('number of data files:', data_lenght)\n",
    "print(np.shape(bold_files[1])[0])\n",
    "print(data_lenght*(np.shape(bold_files[1])[0]))\n",
    "\n",
    "print(type(final_volume_labels))\n",
    "print(len(final_volume_labels))\n",
    "print(np.shape(final_volume_labels))\n",
    "print(final_volume_labels)\n",
    "print(final_bold_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Start Test #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_dict_task_modularity(modality):\n",
    "    \n",
    "    \"\"\"\n",
    "    Building a dictionary for different conditions \n",
    "    of events under different modalities.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    modality: str\n",
    "        e.g. 'motor'\n",
    "    \"\"\"\n",
    "\n",
    "    motor_task_con = {\"response_left_foot\": \"Lfoot_mot\",\n",
    "                      \"response_left_hand\": \"Lhand_mot\",\n",
    "                      \"response_right_foot\": \"Rfoot_mot\",\n",
    "                      \"response_right_hand\": \"Rhand_mot\",\n",
    "                      \"response_tongue\": \"tongue_mot\"}\n",
    "\n",
    "    wm_task_con   =  {\"0-Back_Body\":   \"0Bbody_wm\",\n",
    "                      \"0-Back_Face\":  \"0Bface_wm\",\n",
    "                      \"0-Back_Place\": \"0Bplace_wm\",\n",
    "                      \"0-Back_Tools\":  \"0Btools_wm\",\n",
    "                      \"2-Back_Body\":   \"2Bbody_wm\",\n",
    "                      \"2-Back_Face\":  \"2Bface_wm\",\n",
    "                      \"2-Back_Place\": \"2Bplace_wm\",\n",
    "                      \"2-Back_Tools\":  \"2Btools_wm\"}\n",
    "\n",
    "    lang_task_con =  {\"presentation_math\":  \"math_lang\",\n",
    "                      \"presentation_story\": \"story_lang\"}\n",
    "    \n",
    "    emotion_task_con={\"response_shape\": \"shape_emo\",\n",
    "                      \"response_face\": \"face_emo\"}\n",
    "    \n",
    "    gambl_task_con = {\"Reward\":  \"win_gamb\",\n",
    "                      \"Punishment\": \"loss_gamb\"}\n",
    "    \n",
    "    relation_task_con = {\"match\":    \"match_reson\",\n",
    "                      \"relation\": \"relat_reson\"}\n",
    "    \n",
    "    social_task_con ={\"mental\": \"mental_soc\",\n",
    "                      \"rnd\":  \"random_soc\"}\n",
    "    \n",
    "\n",
    "    dicts = [motor_task_con, lang_task_con, emotion_task_con, \n",
    "             gambl_task_con, relation_task_con, social_task_con, wm_task_con]\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    all_task_con = defaultdict(list)\n",
    "    for d in dicts:\n",
    "        for k, v in d.items():\n",
    "            all_task_con[k].append(v)\n",
    "            \n",
    "#     print('all tasks conditions:')\n",
    "#     all_task_con.items()\n",
    "\n",
    "    mod_chosen = modality[:3].lower().strip()\n",
    "    mod_choices = {'mot': 'MOTOR',\n",
    "                   'lan': 'LANGUAGE',\n",
    "                   'emo': 'EMOTION',\n",
    "                   'gam': 'GAMBLING',\n",
    "                   'rel': 'RELATIONAL',\n",
    "                   'soc': 'SOCIAL',\n",
    "                   'wm': 'WM',\n",
    "                   'all': 'ALLTasks'}\n",
    "    task_choices = {'mot': motor_task_con,\n",
    "                    'lan': lang_task_con,\n",
    "                    'emo': emotion_task_con,\n",
    "                    'gam': gambl_task_con,\n",
    "                    'rel': relation_task_con,\n",
    "                    'soc': social_task_con,\n",
    "                    'wm': wm_task_con,\n",
    "                    'all': all_task_con}\n",
    "\n",
    "    modality = mod_choices.get(mod_chosen, 'default')\n",
    "    task_contrasts = task_choices.get(mod_chosen, 'default')\n",
    "    return task_contrasts, modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality = 'wm'\n",
    "bulid_dict_task_modularity(modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shima, in process\n",
    "def modality_dict(modality):\n",
    "\n",
    "    task_choices = {'motor': motor_task_con,\n",
    "                    'language': lang_task_con,\n",
    "                    'emotion': emotion_task_con,\n",
    "                    'gambling': gambl_task_con,\n",
    "                    'relational': reson_task_con,\n",
    "                    'social': social_task_con,\n",
    "                    'wm': wm_task_con,\n",
    "                    'all': all_task_con}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = \"123 north anywhere street south\"\n",
    "condition = {\"north\":\"N\", \"south\":\"S\" }\n",
    "\n",
    "for word, initial in condition.items():\n",
    "    address = address.replace(word.lower(), initial)\n",
    "print (address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### End test ####################33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl = data_lenght\n",
    "# sh = np.shape(bold_files[1])[0]\n",
    "\n",
    "# Data selection\n",
    "X = final_bold_files\n",
    "y = final_volume_labels\n",
    "\n",
    "# Find unique conditions\n",
    "categories = np.unique(y)\n",
    "unique_conditions, order = np.unique(categories, return_index=True)\n",
    "unique_conditions = unique_conditions[np.argsort(order)]\n",
    "\n",
    "# Encoding the string to numerical values\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "# Reshape y\n",
    "temp = np.reshape(y, (len(final_volume_labels),1))\n",
    "y = temp\n",
    "\n",
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "y = pd.DataFrame(enc.fit_transform(y).toarray())\n",
    "print('label encoded values:', y)\n",
    "\n",
    "# shuffle and split the data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "\n",
    "#standarize features caling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)\n",
    "print(np.shape(X_train))\n",
    "print(type(X_train))\n",
    "\n",
    "print(y_train)\n",
    "print(type(y_train))\n",
    "\n",
    "print(X_test)\n",
    "print(np.shape(X_test))\n",
    "print(type(X_test))\n",
    "\n",
    "print(y_test)\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ANN\n",
    "warnings.filterwarnings('ignore')\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(222 , input_dim = 444, activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(111, activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(55, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(num_cond, activation = 'softmax'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', \n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "# # Fitting the ANN to the Training set\n",
    "history = classifier.fit(X_train, y_train, batch_size = 5, epochs = 5, \n",
    "                         validation_split = 0.1)\n",
    "\n",
    "# # Fitting the ANN to the Training set\n",
    "# history.classifier.fit(X_train, y_train, batch_size = 5, epochs = 10, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions and evaluating the model\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test.values.argmax(axis = 1), y_pred.argmax(axis=1))\n",
    "\n",
    "# normalising confusion matrix\n",
    "cmn = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "print(np.round(cmn, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "df_cm = pd.DataFrame(cmn, index=unique_conditions, columns=unique_conditions)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, cmap='Blues', square=True)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title('Artificial neural networks confusion matrix', fontsize=15, fontweight='bold')\n",
    "plt.xlabel(\"true label\", fontsize= 12, fontweight='bold')\n",
    "plt.ylabel(\"predicted label\", fontsize=12, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data selection\n",
    "X = final_bold_files\n",
    "y = final_volume_labels\n",
    "\n",
    "#shuffle and split the data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#standarize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initializing the SVM\n",
    "model_svm = SVC(C = 1.0, cache_size = 200, class_weight = None, coef0 = 0.0,\n",
    "    decision_function_shape = 'ovo', degree = 3, gamma = 'scale', kernel = 'linear',\n",
    "    max_iter = -1, probability = False, random_state = None, shrinking = True,\n",
    "    tol = 0.001, verbose = False)\n",
    "\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "#accuracy\n",
    "score = model_svm.score(X_test, y_test)\n",
    "\n",
    "#print classification report\n",
    "svm = model_svm.predict(X_test)\n",
    "report = classification_report(y_test, svm)\n",
    "print(report)\n",
    "\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "cv_scores_svm  = cross_val_score(model_svm , X_train, y_train, cv=5) \n",
    "print(cv_scores_svm)\n",
    "\n",
    "# The mean prediction accuracy\n",
    "classification_accuracy_svm  = np.mean(cv_scores_svm )\n",
    "classification_accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalising confusion matrix\n",
    "cm_svm = confusion_matrix(y_test, svm)\n",
    "cmn_svm = cm_svm.astype('float') / cm_svm.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "# plotting\n",
    "plot_matrix(cmn_svm, cmap = 'Blues', labels = unique_conditions)\n",
    "plt.title('SVM Confusion matrix')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.yticks(rotation = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the NN\n",
    "model_nn = MLPClassifier(activation='logistic', alpha=1e-5, batch_size='auto',\n",
    "              beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
    "              epsilon=1e-08, hidden_layer_sizes=(5, 2),\n",
    "              max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
    "              nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
    "              solver='lbfgs', tol=0.0001, validation_fraction=0.1, \n",
    "              verbose=False, warm_start=False)\n",
    "\n",
    "#train model\n",
    "model_nn.fit(X_train, y_train)\n",
    "\n",
    "#accuracy\n",
    "score = model_nn.score(X_test, y_test)\n",
    "\n",
    "#print classification report\n",
    "nn = model_nn.predict(X_test)\n",
    "report = classification_report(y_test, nn)\n",
    "print(report)\n",
    "\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "cv_scores_nn = cross_val_score(model_nn, X_train, y_train, cv=5) \n",
    "print(cv_scores_nn)\n",
    "\n",
    "# The mean prediction accuracy\n",
    "classification_accuracy_nn = np.mean(cv_scores_nn)\n",
    "classification_accuracy_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy_nn = cv_scores_nn * 100\n",
    "print(prediction_accuracy_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalising confusion matrix\n",
    "cm_nn = confusion_matrix(y_test, nn)\n",
    "cmn_nn = cm_nn.astype('float') / cm_nn.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plotting\n",
    "plot_matrix(cmn_nn, cmap='Blues', labels=unique_conditions)\n",
    "plt.title('Neural networks confusion matrix')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark_env",
   "language": "python",
   "name": "benchmark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
