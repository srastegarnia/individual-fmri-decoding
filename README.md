# Brain Decoding of HCP Tasks in a Dense Individual fMRI Dataset
[![DOI](https://img.shields.io/badge/DOI-10.1016%2Fj.neuroimage.2023.120395-blue)](https://doi.org/10.1016/j.neuroimage.2023.120395)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)(https://creativecommons.org/licenses/by/4.0/)
This repository contains the code accompanying the research paper:

**Rastegarnia, S. et al. (2023). Brain decoding of the Human Connectome Project tasks in a dense individual fMRI dataset. NeuroImage, 283, 120395.
DOI: https://doi.org/10.1016/j.neuroimage.2023.120395**

## ğŸ§  Overview
This project demonstrates that highly accurate brain decoding models can be trained entirely at the individual level using densely sampled fMRI data. 
We benchmarked nine machine learning classifiers to decode 21 experimental conditions from the Human Connectome Project (HCP) task battery using one of 
the largest collections of individual multi-task fMRI data available to date (~7 hours per subject).

## Key Findings:
- Item 1 High decoding accuracy (57-67%) using individual models, approaching state-of-the-art group-level models trained on >1000x more data
- Item 2 Multi-Layer Perceptron (MLP) and Graph Convolutional Networks (GCN) were the top-performing models
- Item 3 Models learned highly subject-specific features that did not generalize well across participants
- Item 4 Higher-resolution brain parcellations (e.g., Schaefer-1000) generally yielded better results
- Item 5 Feature importance maps revealed expected brain regions for relevant cognitive domains

## ğŸ“¦ Repository Structure
```text
hcptrt-decoding/
â”œâ”€â”€ benchmark_models/               # Core scripts for data processing and classical ML decoding
â”‚   â”œâ”€â”€ benchmark_decoders.py       # Main script to run all benchmark classifiers
â”‚   â”œâ”€â”€ hcptrt_data_loader.py       # Loads and preprocesses raw fMRI and event data
â”‚   â”œâ”€â”€ hcptrt_data_prep.py         # Prepares processed data for decoding
â”‚   â”œâ”€â”€ beta_maps_benchmark.py      # Script for GLM-based beta map generation
â”‚   â”œâ”€â”€ sanity_check_beta_map.py    # Utility for checking GLM results
â”‚   â””â”€â”€ visualization.py            # Functions for plotting results
â”œâ”€â”€ gcn/                            # Graph Convolutional Network implementation
â”‚   â”œâ”€â”€ test_notebooks/             # Jupyter notebooks for GCN development
â”‚   â”œâ”€â”€ conectomes_generator.py     # Generates functional connectivity matrices
â”‚   â”œâ”€â”€ data_concat_windows_gcn.py  # Prepares data windows for GCN input
â”‚   â”œâ”€â”€ gcn_model.py                # Defines GCN model architectures (PyTorch)
â”‚   â”œâ”€â”€ graph_construction.py       # Utilities for building brain graphs
â”‚   â””â”€â”€ time_windows_dataset.py     # Dataset class for time-windowed data
â”œâ”€â”€ timeseries_benchmark/           # Time series analysis and benchmarking
â”‚   â”œâ”€â”€ All_tasks_hcptrt_extended_benchmark_model.ipynb
â”‚   â”œâ”€â”€ All_tasks_hcptrt_restriced_benchmark_model.ipynb
â”‚   â”œâ”€â”€ benchmark_utils.py          # Utility functions for benchmark analysis
â”‚   â”œâ”€â”€ tbenchmark_all.ipynb        # Comprehensive time series benchmarking
â”‚   â””â”€â”€ outputs/                    # Directory for output files
â”œâ”€â”€ utils.py                        # Shared utility functions
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ README.md
```

## ğŸš€ Getting Started
1. First item Prerequisites
- Item 1 Python 3.7+
- Item 2 The dataset: CNeuroMod hcptrt
* The dense individual fMRI dataset used in this work is publicly available as part of the CNeuroMod databank. 
Access requires an inter-institutional data transfer agreement. See the [CNeuroMod access instructions](https://www.cneuromod.ca/access/).

2. Second item Installation
Clone this repository and install the required Python packages:
```bash
git clone https://github.com/srastegarnia/individual-fmri-decoding.git
cd individual-fmri-decoding
pip install -r requirements.txt
```
## ğŸ”§ Usage
### Pipeline 1: Classical Machine Learning Benchmark
Data Preparation:
```bash
cd benchmark_models
# Run data loading and preparation
```

Running the Benchmark:
```python
for task_label in task_labels:    
    tpl_mask = path + 'mask_file.nii.gz'
    event_file = path + 'events_file.tsv'
    
    # Read conditions and generate beta maps
    df = utils.new_conditions(path, event_file, task_label)
    conditions = list(set(df.trial_type))
    utils.postproc_task(subject, task_label, conditions, tpl_mask)
    
    # Run decoder
    utils.check_decoding(subject, task_dir, task_label, tpl_mask)
```

## ğŸ“Š Outputs
The pipelines generate:
- Item 1 **Processed Data:** NumPy arrays (.npy) and CSV files
- Item 2 **Functional Connectomes:** Adjacency matrices
- Item 3 **Beta Maps:** GLM-generated condition maps
- Item 4 **Results Summary:** Accuracy metrics
- Item 5 **Visualizations:** Confusion matrices, training plots
- Item 6 **Trained Models:** Saved model weights

## ğŸ¤ Contributing
Contributions to improve the code or extend the benchmarks are welcome. Please fork the repository and submit a Pull Request.


## ğŸ“œ License
This code repository is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

The associated research paper is licensed under **Creative Commons Attribution 4.0 International (CC BY 4.0)**.

## ğŸ™ Acknowledgments
This work is part of the Courtois Project on Neuronal Modeling (CNeuroMod), made possible by a generous donation from the Courtois Foundation.

**Funding:** Courtois Foundation, Fonds de recherche du QuÃ©bec - SantÃ© (FRQS), Wu Tsai Neurosciences Institute
**Computing:** Digital Research Alliance of Canada (formerly Compute Canada), Calcul QuÃ©bec
**Data:** The CNeuroMod team and all research participants

## ğŸ“« Contact
- Item 1 Shima Rastegarnia: srastegarnia@gmail.com
Please cite our work if you use this code:
``` bibtex
@article{Rastegarnia2023,
  title = {Brain decoding of the Human Connectome Project tasks in a dense individual fMRI dataset},
  journal = {NeuroImage},
  volume = {283},
  pages = {120395},
  year = {2023},
  author = {Shima Rastegarnia and Marie St-Laurent and Elizabeth DuPre and Basile Pinsard and Pierre Bellec},
  doi = {https://doi.org/10.1016/j.neuroimage.2023.120395}
}
```

